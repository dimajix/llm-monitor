logging:
  format: "text"  # or "text" for text format

proxy:
  port: 8080
  upstream:
    url: "${UPSTREAM_URL:-http://localhost:11434}"
    timeout: "600s"
  intercepts:
    - endpoint: "/api/users"
      method: "*"
      interceptor: "CustomInterceptor"
    - endpoint: "/api/products"
      method: "*"
      interceptor: "SimpleInterceptor"
    - endpoint: "/api/logs"
      method: "*"
      interceptor: "LoggingInterceptor"
    - endpoint: "/api/generate"
      method: "POST"
      interceptor: "OllamaGenerateInterceptor"
    - endpoint: "/api/chat"
      method: "POST"
      interceptor: "OllamaChatInterceptor"
    - endpoint: "/v1/chat/completions"
      method: "POST"
      interceptor: "OpenAIChatInterceptor"

api:
  port: 8081

storage:
  type: "postgres"
  timeout: "500s"
  postgres:
    dsn: "postgres://${DB_USER:-llm_user}:${DB_PASSWORD:-llm_pass}@${DB_HOST:-localhost}:${DB_PORT:-5432}/${DB_NAME:-llm_monitor}?sslmode=disable"
